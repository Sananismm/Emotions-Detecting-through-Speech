

# ğŸ­ Speech Emotion Recognition System

**Signals & Systems Project | Real-Time Emotion Detection from Speech**

---

## ğŸ“Œ Overview

This project implements a **Speech Emotion Recognition (SER)** system that classifies human emotions from spoken audio signals.
It combines **classical signal processing techniques** with **machine learning** and **deep learning**, and is deployed as an **interactive Streamlit web application**.

The system supports:

* ğŸ“ Emotion detection from uploaded WAV files
* ğŸ™ï¸ Real-time emotion detection from live microphone input (local execution)
* ğŸ”€ Model switching between:

  * **SVM with MFCC-based DSP features**
  * **CNN with Mel-Spectrogram inputs**

The project uses the **RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)** dataset for training and evaluation.

---

## ğŸ§  Models Implemented

### 1ï¸âƒ£ SVM (Classical DSP + Machine Learning)

* Features:

  * MFCCs
  * Delta MFCCs
  * Zero-Crossing Rate
  * Spectral Centroid
  * Spectral Bandwidth
* Feature normalization using `StandardScaler`
* Classifier: Support Vector Machine (SVM)
* Strengths:

  * Interpretable
  * Lightweight
  * Strong signal-processing foundation

---

### 2ï¸âƒ£ CNN (Deep Learning)

* Input representation: **Log Mel-Spectrograms**
* Architecture:

  * 2D Convolutional layers
  * Max pooling
  * Dense layers with softmax output
* Achieved accuracy: **~83%**
* Strengths:

  * Learns timeâ€“frequency patterns automatically
  * Higher accuracy than classical approach

---

## ğŸ“Š Signal Processing Pipeline

### SVM Pipeline

```
Raw Audio
 â†’ Silence Trimming
 â†’ Normalization
 â†’ MFCC + Spectral Feature Extraction
 â†’ Feature Scaling
 â†’ SVM Classification
```

### CNN Pipeline

```
Raw Audio
 â†’ Silence Trimming
 â†’ Normalization
 â†’ Mel-Spectrogram
 â†’ Log Scaling
 â†’ CNN Inference
```

---

## ğŸ–¥ï¸ Web Application (Streamlit)

The Streamlit app provides:

* Model selection (SVM / CNN)
* Upload-based emotion detection
* Live microphone recording (local execution only)
* Visualization of:

  * Waveform
  * Spectrogram / Mel-Spectrogram
  * Emotion probability distribution

---

## ğŸ“‚ Project Structure

```text
emotion_speech_project/
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py        # Main Streamlit application
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ svm_ravdess.joblib      # Trained SVM model
â”‚   â”œâ”€â”€ scaler.joblib           # Feature scaler
â”‚   â”œâ”€â”€ cnn_emotion_model_83.h5 # Trained CNN model
â”‚   â””â”€â”€ cnn_label_encoder.pkl   # CNN label encoder
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_train_SVM.ipynb      # Feature extraction & SVM training
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ feature utilities      # Signal processing helpers
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ RAVDESS/                # Dataset (not included in repo)
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“¦ Requirements

See `requirements.txt`.

Key dependencies:

* Python 3.9+
* Streamlit
* Librosa
* NumPy
* Scikit-learn
* TensorFlow
* Matplotlib
* SoundDevice (local recording only)

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/your-username/speech-emotion-recognition.git
cd speech-emotion-recognition
```

### 2ï¸âƒ£ Create and activate virtual environment

```bash
python -m venv venv
venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run the Streamlit app

```bash
streamlit run app/streamlit_app.py
```

---

## ğŸ™ï¸ Live Recording Support

* Live microphone recording works **only on local machines**
* Disabled automatically on cloud deployments
* Upload-based inference works everywhere

---

## ğŸ“ˆ Dataset

* **RAVDESS Dataset**
* Emotions include:

  * Neutral
  * Calm
  * Happy
  * Sad
  * Angry
  * Fearful
  * Disgust
  * Surprised

Dataset is not included due to licensing.

---

## ğŸ“ Academic Context

This project was developed as part of a **Signals & Systems course**, with emphasis on:

* Time-domain and frequency-domain analysis
* Feature extraction from audio signals
* Practical application of DSP concepts
* Comparison of classical ML vs deep learning

---

## ğŸš€ Future Improvements

* Browser-based microphone recording
* Data augmentation
* Transfer learning (pretrained audio CNNs)
* Real-time emotion timeline visualization
* Multi-language emotion recognition

---

## ğŸ‘¨â€ğŸ’» Author

**Muhammad Sanan Khan**
Electrical Engineering
Speech & Signal Processing Project

---

## ğŸ“œ License

This project is for **educational and research purposes only**.


Just say the word ğŸ‘
